\documentclass[a4paper,11pt,spanish, twoside, leqno]{tfg-uam}

\usepackage[utf8]{inputenc}
\usepackage{amsfonts, amssymb, amsmath, amsthm}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multicol}

\newtheorem{teor}{Teorema}[chapter]
\newtheorem{lema}[teor]{Lema}
\newtheorem*{teorsin}{Teorema}


\theoremstyle{definition}
\newtheorem{defin}[teor]{Definici\'on}

\title{Combinaciones de expertos aplicados al problema de regresi\'on}
\author{Jos\'e Benjumeda Rubio}
\tutor{José Luis Torrecilla Noguerales y Luis Alberto Rodr\'iguez Ram\'irez}
\curso{2020-2021}


%%%%%METADATOS: rellenar la info solicitada entre llaves
\usepackage{hyperref}
\hypersetup{
	pdfinfo={
            Title={ }, %Titulo del trabajo; ejemplo: Matematicas y desarrollo
            Author={ }, %Autor del trabajo; ejemplo: Juan Sanchez
            Director1={ }, %Tutor1: en formato nombre.apellido, tal como aparece en la primera parte, antes de la arroba,  de su direccin de correo electrnico de la UAM; ejemplo: fernando.soria
            Director2={ }, %Tutor2: en formato nombre.apellido, tal como aparece en la primera parte, antes de la arroba,  de su direccin de correo electrnico de la UAM
            Ndirectores={ }, %Numero total de directores: 1  2
            Tipo={TFG}, %no tocar
            Curso={2018-19}, %no tocar
            Palabrasclave={ },% Palabras clave del trabajo, separadas por comas y sin acentos ni espacios; ejemplo: morfismos, formas modulares, ecuaciones elipticas
				}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}




\begin{abstract}[spanish]
Aliquam lorem ante, dapibus in, viverra quis, feugiat a, tellus.
\end{abstract}
\begin{abstract}[english]
Etiam rhoncus. \end{abstract}


\mainmatter

\newpage
La mayor parte de la introducción ha sido obtenida del capítulo 3, \textit{Linear regression}, del libro \textit{An Introduction to Statistical Learning: With Applications in R}. \cite{Has}

\chapter{Introducción}\label{chap1}
\setcounter{page}{1}

\paragraph{} La estadística y el análisis de datos permiten llegar cada vez más lejos en el desarrollo de inteligencia artificial, buscando combinar el razonamiento humano con la velocidad y capacidad de procesamiento de una máquina. En este trabajo se desarrollará un método de ensemble que aprenderá la relación entre un conjunto de datos conocidos para obtener otros desconocidos, es decir, se estudiará el problema de regresión. 

\paragraph{} Tras explicar el contexto estadístico sobre el que se define el problema de regresión, se explicarán los modelos que compondrán el método de ensemble: el perceptrón simple y la \emph{Support Vector Machine}, que implementan de dos maneras distintas una poderosa idea: la transformación no lineal adecuada permite obtener a partir de unos datos que no pueden explicarse de manera lineal, otros que sí se pueden aproximar satisfactoriamente mediante un modelo lineal.

\paragraph{} Para dar apoyo a las explicaciones teóricas, entrenaremos estos modelos para aprender la relación entre la cantidad de energía eólica obtenida cada hora de cada día en el parque eólico experimental de Sotavento, en Galicia, y las predicciones de los valores de módulo y dirección del vector de viento medido tanto a 10 como a 100 metros de altura, la temperatura medida a 2 metros de altura y la presión en la superficie.


\section{Estado del arte: modelos de ensemble}

\section{El problema de regresión}

\paragraph{} Un \textit{problema de regresión} consiste en asignar a una nueva observación de una variable aleatoria un valor numérico, a partir de la información proporcionada por otras variables aleatorias. Esto nos lleva a las primeras definiciones:

\begin{defin}
Dado un espacio de probabilidad $(\Omega ,{\mathcal {A}},P)$, y un espacio medible $(S, \Sigma)$, una \textit{variable aleatoria} X es una función 
\[
    X: \Omega \rightarrow S
\]
que es $\mathcal{A}/\Sigma$-medible. Si S es $\mathbb{R}$ y $\Sigma$ es $\mathcal{B}(\mathbb{R})$, X es una variable aleatoria real.
\end{defin}

\paragraph{} Nos referiremos a las distintas variables aleatorias, cuando haya más de una, con superíndices, por ejemplo $X^1, X^2, \ldots, X^p$, y a repeticiones de una misma variable aleatoria, por ejemplo de $X^1$, con subíndices, como $X^1_1, X^1_2, \ldots, X^1_n$.

\begin{defin}\label{D_n}
    Dadas las variables aleatorias reales $X^1, X^2, \ldots, X^p, Y$, definimos una muestra de datos de tamaño $n$ como
    \begin{equation}
        D_n = \{( \boldsymbol x_1, y_1), (\boldsymbol x_2, y_2), \ldots, (\boldsymbol x_n, y_n) \} \subset \mathbb{R}^p \times \mathbb{R}
        ,
    \end{equation}
    donde 
    \begin{equation*}
        (\boldsymbol x_i, y_i) = (x^1_i, x^2_i, \ldots, x^p_i, y_i)
    \end{equation*}
\end{defin}

\begin{defin}
    Dadas $p+1$ variables aleatorias reales, $X^1, X^2, \ldots, X^p, Y$, de las que conocemos una muestra $D_n$, y una función distancia $d: \mathbb{R} \times \mathbb{R} \to \mathbb{R}^+$, un problema de regresión es aquel en el que a partir de la información de la muestra, se busca una función 
    \begin{align*}
        f:\mathbb{R}^p \; &\to \;\; \mathbb{R} \\
        \boldsymbol x \;\; & \mapsto f(\boldsymbol x)
    \end{align*}
    que minimice $d(f(\boldsymbol x_i), y_i)$, con $(\boldsymbol x_i, y_i)$ una observación que puede pertenecer o no a la muestra.
\end{defin}

\paragraph{} Intentamos buscar una solución a un problema de regresión a partir de la hipótesis de que el comportamiento de las variables independientes nos indica en cierta medida el comportamiento de la variable dependiente.

\paragraph{} Una primera clasificación entre los problemas de regresión, es aquella que distingue entre problemas de regresión lineal y problemas de regresión no lineal. El tipo de regresión a utilizar para resolver un problema viene determinado por la relación que haya entre los datos: si un porcentaje alto de ésta es lineal, obtendremos buenos resultados con una función de regresión lineal, pero en casos en los que la relación sea altamente no lineal, con una función lineal no conseguiremos buenos resultados, al menos de manera directa. Por lo tanto, antes de buscar ninguna solución, hay que realizar un estudio de los datos. La forma que tengan nos dará una primera intuición sobre si debemos buscar una función lineal o una no lineal.

\paragraph{} Muchos métodos para resolver problemas de regresión no lineales se basan en transformar los datos de manera que se puedan resolver con un modelo linea. Muchos modelos no lineales son en realidad un modelo lineal con una pequeña modificación, como por ejemplo el caso de la regresión regularizada. Por este motivo, este trabajo comienza definiendo la regresión lineal simple, que trata el caso de un problema lineal donde $p=1$, es decir, hay una única variable aleatoria independiente, y la regresión lineal múltiple o regresión lineal, donde se estudia un problema de regresión lineal con $p>1$.

\subsubsection{Regresión lineal simple}

\paragraph{} En un problema de regresión lineal simple se busca explicar una variable aleatoria, Y, a partir de otra, X, asumiendo una relación lineal entre ambas más un error que sigue una distribución normal de media 0:
%
\[
    Y = f(X) = \beta_0 + \beta_1X + \epsilon
    ,
\]
%
donde $\beta_0$ es el corte de la recta con el eje OY y $\beta_1$ es la pendiente de la recta, y $f(X)$ es el modelo lineal. Que exista este $\epsilon$ significa que la variable aleatoria X explica un cierto porcentaje de Y, que rara vez será su totalidad.

\paragraph{} En el contexto habitual de un problema de regresión lineal, no conocemos los valores de $\beta_0$ ni de $\beta_1$, así que los estimamos mediante $\hat{\beta}_0$ y $\hat{\beta}_1$. 

\paragraph{} Dado que queremos estudiar una muestra de datos genérica, ya no escribiremos las observaciones como $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$, sino que trataremos cada observación como a la variable aleatoria que gobierna su comportamiento. Es decir, escribiremos cada observación $(x_i, y_i)$ como $(X_i, Y_i)$. Por tanto, la muestra de datos es
\begin{equation}
    D_n = \{( X_1, Y_1), (X_2, Y_2), \ldots, (X_n, Y_n) \} \subset \mathbb{R} \times \mathbb{R}
    .
\end{equation}
%
donde nos referiremos a $X_i$ como la observación $i$, y a $Y_i$ como el \textit{target} de la observación $i$.

\paragraph{} Ahora obtendremos valores para  $\hat{\beta}_0$ y $\hat{\beta}_1$ minimizando el error cuadrático medio visto como función de $\hat{\beta}_0$ y $\hat{\beta}_1$, sobre la muestra $D_n$:

\begin{equation}
    J(\hat{\beta_0}, \hat{\beta_1})
    = \frac1n \sum_{i=1}^n (Y_i - (\hat{\beta_0} + \hat{\beta_1} X_i))^2
    .
\end{equation}

\paragraph{} Estudiando la forma de esta función, vemos que dicho mínimo siempre existirá:

\begin{equation}    
    \begin{aligned}
        J(\hat \beta_0, \hat \beta_1)
        & = \frac{1}{n}\sum_{i=1}^{n}(Y_i - (\hat \beta_0 + \hat \beta_1 X_i))^2
        = \\
        & = \frac1n \sum_{i=1}^n (Y_i^2 + \hat \beta_0^2 + \hat \beta_1^2 X_i^2 + 2 \hat \beta_0 \hat \beta_1 X_i - 2 \hat \beta_0 Y_i - 2 \hat \beta_1 Y_i X_i)
        = \\
        & = E[Y^2] + \hat \beta_0^2 + \hat \beta_1^2 E[X^2] +2 \hat \beta_0 \hat \beta_1 E[X] - 2 \hat \beta_0 E[Y] - 2 \hat \beta_1 E[XY]
        = \\
        & = (\hat \beta_0, \hat \beta_1)
        \begin{pmatrix}
            1 & E[X]
            \\ E[X] & E[X^2]
        \end{pmatrix}
        \begin{pmatrix}
            \hat \beta_0 \\ \hat \beta_1 
        \end{pmatrix}
        - 2 E[Y] \hat \beta_0 - 2 E[XY] \hat \beta_1 + E[Y^2]
        .
    \end{aligned}
\end{equation}

\paragraph{} El primer término,
%
\begin{equation}
    (\hat \beta_0, \hat \beta_1)
    \begin{pmatrix}
        1 & E[X]
        \\ E[X] & E[X^2]
    \end{pmatrix}
    \begin{pmatrix}
        \hat \beta_0
        \\ \hat \beta_1 
    \end{pmatrix}
    ,
\end{equation}
%
es una forma cuadrática definida positiva, pues su determinante es la varianza de $X$, que es positiva. Por esto sabemos que tiene un mínimo.

\paragraph{} Los otros dos términos lineales y el término constante no cambian este hecho, ya que al derivar, su efecto es el de sumar constantes a una ecuación lineal, y esto no cambia la cantidad de ceros de la ecuación.

\paragraph{} Derivamos respecto de $\hat \beta_0$ y de $\hat \beta_1$ y obtenemos los valores en que hacen mínimo el error cuadrático:

\[
    \frac{ \partial } { \partial \hat \beta_0 } J(\hat \beta_0, \hat \beta_1)
    = 2\hat \beta_0 + 2 E[X] \hat \beta_1 - 2 E[Y]
    = 0
\]

\[
    \frac{ \partial } { \partial \hat \beta_1 } J(\hat \beta_0, \hat \beta_1)
    = 2\beta_0 E[X] + 2 E[X^2] \hat \beta_1 - 2 E[XY]
    = 0
\]

\begin{equation}
    \hat \beta_0
    = E[Y] - E[X] \frac{ COV(X, Y) } { \sigma^2 (X) }
\end{equation}

\begin{equation}
    \hat \beta_1
    = \frac{ E[XY] - E[X] \; E[Y] }{ E[X^2] - E[X]^2 }
    = \frac{ COV(X, Y) }{ \sigma^2 (X) }
    .
\end{equation}

\paragraph{} Estos estimadores son insesgados, es decir, $E[\hat \beta_0] = \beta_0$ y $E[\hat \beta_1] = \beta_1$. Sin embargo, en muchas ocasiones vamos a hacer una única estimación, así que también nos interesa saber cómo de lejos del valor poblacional estará una estimación cualquiera. Para esto, miramos la varianza, que tiene la siguiente fórmula:

\[
    \sigma^2( \hat{ \beta }_0 )
    = \sigma^2(\epsilon) \left(\frac {1} {n} + \frac { E[X]^2 } { \sigma^2(X) } \right) \;\;\;\;\;\;\;\;\; \sigma^2( \hat{ \beta }_1 )
    = \frac { \sigma^2(\epsilon) } { \sigma^2(X) }
    .
\]

\paragraph{} Ambas fórmulas tienen la condición de que el error $\epsilon$ y la covarianza sean incorrelados, aunque incluso si esto no ocurre es probable que obtengamos buenas aproximaciones utilizándolas.

\paragraph{} De ellas podemos destacar que al estar la varianza de $X$ en el denominador, nos beneficia que sea lo mayor posible: cuanto más extendidas estén las muestras de X, mejor estimaremos los parámetros. Podemos imaginar que queremos trazar una recta uniendo dos puntos: cuando estos están muy cerca, un pequeño error lleva a una recta muy diferente de la correcta, y en cambio, si están lejos, para que la recta varíe tanto necesitaríamos haber cometido un error mucho más grande.

\paragraph{} Normalmente, $\epsilon$ es desconocido, y se estima a partir de la muestra utilizando el error cuadrático J para $\beta_0$ y $\beta_1$ fijos:

\[ 
    \hat \epsilon = \sqrt{ \frac {J(\hat \beta_0, \hat \beta_1)} {n-2} } 
    .
\]

A partir de la varianza de los estimadores obtenemos un intervalo de confianza del 95\% muy sencillo:
\paragraph{} Para $\beta_0: \;\;\;\;\; \hat{\beta}_0 \pm 2\sigma( \hat{ \beta }_0 ).
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\mbox{Para} \; \beta_1: \;\;\;\;\; \hat{\beta}_1 \pm 2\sigma(\hat{\beta}_1). $

\paragraph{} Los errores cuadráticos también son útiles a la hora de hacer contraste de hipótesis, que consiste en formular una hipótesis o afirmación sobre los datos, y comprobar si estos aportan, una vez fijado cierto nivel de confianza, suficiente evidencia como para probar que la afirmación es falsa, es decir, rechazar $H_0$ y aceptar la contraria, $H_1$.

\paragraph{} Un contraste de hipótesis muy frecuente es afirmar que no existe ninguna relación entre X e Y:
\[
    H_0 \;\; \equiv \;\; \beta_1 = 0
\]
\[
    H_1 \;\; \equiv \;\; \beta_1 \neq 0
    .
\]

Para comprobar la hipótesis alternativa, tenemos que asegurarnos de que $\beta_1$ está lo suficientemente lejos de 0 como para estar seguros de que no ha sido fruto del azar. Para esto, suponemos que $\beta_1$ sí que es 0, y damos un intervalo de confianza $\alpha$ en el que obtendremos nuestra estimación si éste es el caso. Si la estimación que obtenemos a partir de la muestra no pertenece al intervalo, entonces rechazamos.

El tamaño del intervalo de confianza está directamente relacionado con la varianza de nuestro estimador. Si la varianza es alta, es probable que teniendo, por ejemplo,  $\beta_1 = 0$, obtengamos una estimación $\hat{\beta}_1 >> 0$, con lo cual, será más difícil rechazar la hipótesis, y el intervalo de confianza $\alpha$ será mayor. En cambio, si tenemos una varianza muy cercana a cero, muestras que nos proporcionen estimaciones también cercanas a cero pueden ser suficiente para descartar $H_0$.

\paragraph{} Utilizaremos el estadístico 
\begin{equation}
    t = \frac {\hat{\beta}_1 - 0} {\sigma(\hat{\beta}_1)}
\end{equation}
%
para ver cuántas $\sigma(\hat{\beta}_1)$ dista $\hat{\beta}_1$ de 0. Si verdaderamente no hay ninguna relación entre X e Y, es decir, si $\hat{\beta}_1$ es 0, esperamos tener una distribución t-student, con n-2 grados de libertad, que significa que lo más probable es obtener valores muy cercanos a 0 o el propio 0, sin importar si son algo mayores o algo menores (esta distribución es simétrica), y los que se vayan alejando más serán mucho menos probables. A partir de $\pm$30, la t-student y la normal(0,1) son muy similares. 

\paragraph{} Como tenemos una distribución fija conocida, podemos calcular la probabilidad de cada valor obtenido. Si, por ejemplo, el intervalo de confianza es del 95\% y obtenemos un valor de $\hat{\beta}_1$ que pertenezca a $t_{\alpha/2}$ o a $t_{1-\alpha/2} = -t_{\alpha/2}$, descartamos la hipótesis.

\subsubsection{Regresión lineal múltiple}

\paragraph{} La regresión lineal múltiple contempla el problema en el que hay que predecir el valor de una variable dependiente $Y$ a partir de $p$ variables independientes $X^1, X^2, \ldots, X^p$. En este caso volvemos a escribir la muestra en mayúscula, para utilizar las propiedades de las variables aleatorias:

\begin{equation}
    D_n = \{(\boldsymbol X_1, Y_1), (\boldsymbol X_2, Y_2), \ldots, (\boldsymbol X_n, Y_n) \} \subset \mathbb{R}^p \times \mathbb{R}
    ,
\end{equation}
%
donde
\begin{equation}
    (\boldsymbol X_i, Y_i) = (X_i^1, X_i^2, \ldots, X_i^p, Y_i).
\end{equation}

\paragraph{} Una primera aproximación a este problema sería hacer $p$ regresiones lineales independientes, pero habría que decidir cómo predecir el valor de la variable respuesta de cada observación, pues al tener $p$ modelos, obtenemos $p$ predicciones. Además, cada predicción se basaría en una sola variable, ignorando las otras, y esto puede reducir la calidad de las predicciones si las variables tienen correlación unas con otras. 

\paragraph{} La solución que utilizaremos es adaptar el modelo de regresión simple para que en lugar de tener una función de una sola variable, tengamos una función vectorial

\begin{equation}
    Y
    = \beta_0 + \boldsymbol \beta \boldsymbol X + \epsilon
    = \beta_0 + \sum_{i=1}^p \beta_iX^i + \epsilon
    .
\end{equation}

Donde $X^i$ representa la i-ésima variable, y $\beta_i$ cuantifica la asociación entre esa variable y la variable respuesta. La interpretación de $\beta_i$ es el efecto medio sobre Y de un incremento de una unidad sobre la variable $X^i$, manteniendo fijos los demás parámetros.

\paragraph{} En la práctica, igual que ocurría con la regresión lineal simple, los coeficientes de regresión son desconocidos, y tenemos que estimarlos. Procedemos de la misma manera, minimizando el error cuadrático esta vez como función de $p$ variables:
\[ 
    J(\hat \beta_0, \hat \beta_1, , \ldots, \hat \beta_p)
    = \sum_{i=1}^{n} (Y_i - \hat{Y}_i)^2
    = \sum_{i=1}^{n} (Y_i - \hat{\beta}_0 - \sum_{j=1}^p \beta_jX^j_i)^2
    .
\]

\paragraph{} Al contrario que con la estimación simple, las fórmulas que nos permiten minimizar esta ecuación y obtener las estimaciones de los $p+1$ parámetros son bastante complicadas, y, dado que las podemos obtener mediante cualquier software de estadística, no las incluiremos aquí.

\paragraph{} Puede ser que de entre las variables independientes que estudiamos, haya algunas que no tengan relación con la variable independiente, incluso puede que sean todas. Para esto hacemos el contraste de hipótesis
\[
    H_0 : \hat \beta_1 = \hat \beta_2 = \ldots = \hat \beta_p = 0
\]
\[
    H_1 : \exists \; i : \hat \beta_i \neq 0.
\]

\paragraph{} Para testear esta hipótesis utilizamos el estadístico F, que se define como
\[
    F = \frac {(n \sigma^2(Y) - J(\hat \beta_0, \hat \beta_1, , \ldots, \hat \beta_p))/p} {J(\hat \beta_0, \hat \beta_1, , \ldots, \hat \beta_p)/(n-p-1)}
    .
\]

\paragraph{} Si la suposición de linealidad es correcta y $H_0$ es cierta, se cumple
\begin{equation}
    E[J(\hat \beta_0, \hat \beta_1, , \ldots, \hat \beta_p)/(n-p-1)]
    = E[(n \sigma^2(Y) - J(\hat \beta_0, \hat \beta_1, , \ldots, \hat \beta_p))/p]
    .
\end{equation}

\paragraph{} Por lo tanto, si el estadístico F tiene un valor lejos de 1, podemos rechazar $H_0$, y si no, no. ¿Cómo de lejos? Depende de n y p. Cuanto más grande sea n, menos lejos tendrá que estar, y al contrario con p.
\paragraph{} Cuando $H_0$ es cierta y los errores $\epsilon_i$ se distribuyen como una normal, el estadístico F sigue una distribución de Fisher-Snedecor, y podemos calcular el p-valor y utilizarlo para decidir si rechazamos $H_0$ o no. Cuanto más cerca de 0 esté el p-valor, mayor evidencia tenemos para rechazar $H_0$.

\paragraph{} Hay veces que queremos comprobar si un subconjunto de $q$ variables independientes no tienen relación con la variable dependiente. Para ello hacemos el contraste de hipótesis

\begin{equation}
    H_0 : \beta_{p-q+1} = \beta_{p-q+2} = \ldots = \beta_p = 0,
\end{equation}
%
donde $H_0$ está escrita suponiendo que las $q$ variables que queremos estudiar están al final del conjunto de todas las variables (y por tanto los coeficientes también).

\paragraph{} Ahora, para un segundo modelo que utiliza todas las variables excepto las $q$ últimas, tenemos:

\[
    F
    = \frac {(J(\hat \beta_0, \hat \beta_1, , \ldots, \hat \beta_{p-1}) - J(\hat \beta_0, \hat \beta_1, , \ldots, \hat \beta_n))/q} {J(\hat \beta_0, \hat \beta_1, , \ldots, \hat \beta_n)/(n - p - 1)}
    .
\]
Este estadístico F nos dice el efecto de añadir estas q variables a un modelo en el que ya estaban todas las demás.

\paragraph{} Sin embargo, parece que la información que nos da el estadístico F, ya la hemos obtenido en otro momento, al calcular cada coeficiente $\beta_i$ como el incremento medio de la respuesta al incrementar en una unidad la variable $X_i$, estando fijas las demás, así que, ¿que nos aporta el estadístico F que no tengamos ya?

\paragraph{} La respuesta la tenemos al observar un modelo con muchas variables: digamos $P = 100$. Vamos a suponer además, que ninguna de estas variables tiene relación alguna con la variable respuesta, es decir, $\beta_1 = \beta_2 = \ldots = \beta_p = 0$. En este caso, si fijamos un nivel de confianza del $95\%$, un $5\%$ de los valores que obtengamos estarán fuera de este intervalo, con lo que el p-valor sería inferior a 0,05.

\paragraph{} Si obtenemos 100 muestras, es muy probable que obtengamos al menos un p-valor inferior a 0,05 que nos indicaría que los datos aportan una fuerte evidencia para rechazar $H_0$, y pensaríamos que la variable correspondiente nos aporta información sobre la variable respuesta, cosa que es un error.

\paragraph{} Esto no ocurre con el estadístico F, que tiene en cuenta la cantidad de variables, y haya la cantidad que haya, la probabilidad de obtener un p-valor inferior a 0,05 es del 5\%. Tenemos un 95\% de probabilidad de acertar.

\paragraph{} Por último, y muy importante, el estadístico F funciona cuando p es "relativamente" pequeño (con 100 aún funciona bien), y mucho más pequeño si lo comparamos con n. Cuando p se acerca a n o incluso lo supera, tenemos que utilizar otras técnicas, y no podemos aplicar casi nada de lo que se ha visto  hasta ahora.

\subsubsection{Preprocesamiento de datos: Estandarización}

\paragraph{} En el siguiente capítulo estudiaremos la regresión regularizada, el perceptrón multicapa y las máquinas de vectores soporte de regresión. Estos modelos son más complejos que la regresión multilineal, y para utilizarlos es importante regularizar nuestros datos.

\paragraph{} Estos modelos estudian la relación que hay entre los valores de las variables independientes y las variables respuestas, y normalmente tienden a dar más peso a las variables que tengan valores más grandes. 

\paragraph{} Sin embargo, lo grandes que sean los valores de una variable dependerán de las unidades de medida. Si la altura se mide en metros podemos obtener valores entre 1,5 y 2, mientras que si se mide en centímetros, estos estarán entre 150 y 200. No tiene sentido que un modelo de más importancia a la misma información según las unidades en que esté expresada.

\paragraph{} La solución a esto es estandarizar los datos: restamos a cada variable su media y dividimos por su desviación típica, de manera que la variable tenga media 0 y varianza 1, y por lo tanto todas las magnitudes estén alrededor del 0, alejándose una media de una unidad.


\subsection{Elección de hiperparámetros: validación cruzada}

\paragraph{} Como ya hemos dicho, los modelos que vamos a estudiar tienen hiperparámetros, que influyen en gran medida en las predicciones que obtendremos. Para seleccionar qué valor deben tener los hiperparámetros de un modelo, utilizamos la validación cruzada.

\paragraph{} Para definir la validación cruzada definiremos primero las particiones \textit{leave-one-out} y luego un modelo de regresión como una aplicación $G$. Además, utilizaremos estas dos proyecciones que harán más sencillas las explicaciones:

\begin{align}
    \begin{split}
        \pi_X : \mathbb{R}^{d} \times \mathbb{R}  &\to \mathbb{R}^{d}\\
        (\boldsymbol{X_i}, Y_i) &\mapsto \boldsymbol{X_i}
    \end{split}
    \;,
\end{align}

\begin{align}
    \begin{split}
        \pi_Y : \mathbb{R}^d \times \mathbb{R} &\to \mathbb{R}\\
        (\boldsymbol{X_i}, Y_i) &\mapsto Y_i
    \end{split}
    \;.
\end{align}

\paragraph{} Sobre nuestra muestra $D_n$, tomaremos $r$ particiones leave-one-out, donde, como regla general, $r = \#(D_{train})$. A estas $r$ particiones las representaremos mediante la letra $\theta$, como $\theta_1, \theta_2, \ldots, \theta_r$. Esta manera de particionar consiste en dividir $D_{train}$ en dos subconjuntos disjuntos: el conjunto de validación y el conjunto de entrenamiento.

\paragraph{} Para la partición $\theta_i$, al conjunto de entrenamiento lo llamamos $\theta_{itrain}$, y al de validación, $\theta_{ival}$. Los elementos que componen cada subconjunto son:

\begin{align}
    \begin{split}
        \theta_{ival} =& \; \{(\boldsymbol{X_i}, Y_i)\} \\
        \theta_{itrain} =& \; D_{train} \setminus \theta_{ival}.
    \end{split}
\end{align}

\paragraph{} Es importante notar que se tienen que cumplir estas dos condiciones: 
\begin{enumerate}
    \item $\theta_{ival} \neq \theta_{jval}$ siempre que $i \neq j$.
    \item $\bigcup_{i=1}^r \theta_{ival} = D_{train}$, ya que $r = \#(D_{train})$.
\end{enumerate}



\paragraph{} Ahora, para un conjunto de entrenamiento $\theta_{itrain}$ de $m$ observaciones y una partición $\theta_i$, definimos función de regresión
\begin{align}
    g_m :  \{\theta_{itrain}; \; \pi_X(\theta_{ival})\} \to \mathbb{R}
\end{align}
%
como una función que se entrena sobre un conjunto de $m$ observaciones, $\theta_{itrain}$ y da una predicción del target de $\pi_X(\theta_{ival})$.

\paragraph{} A partir de $g_m$, definimos modelo de regresión individual
\begin{equation}
    G = \{g_i\}_{i=1}^\infty
    ,
\end{equation}
%
donde $\{g_i\}_{i=1}^\infty$ es una familia de funciones de regresión de cardinal numerable. El objetivo de $G$ es que se utilice como una función de regresión $g_m$ para un $m$ genérico. $g_m$ se puede aplicar cuando $\#(\theta_{itrain}) = m$, sin embargo, $G$ se puede aplicar para un $\theta_{itrain}$ de cualquier tamaño. Aunque esto suene algo enrevesado, más adelante, en los modelos de ensemble, entrenaremos un mismo modelo sobre distintos conjuntos de aprendizaje, con lo que esta definición es necesaria.

\paragraph{} $G(\theta_{itrain}, \pi_X(\theta_{ival}))$ equivale a la salida de la función m-ésima de $G$ para los mismos parámetros, con $m = \#(\theta_{itrain})$.

\paragraph{} Volvemos a los hiperparámetros: definimos un conjunto finito de posible valores para los hiperparámetros que queremos calibrar, y definir un modelo con cada posible combinación. Digamos que obtenemos una familia de modelos de regresión ${G_1, G_2, \ldots, G_k}$. 

\paragraph{} Ahora damos a cada modelo una puntuación que mide cómo de bien predice ese modelo el target de una observación cuando se ha entrenado con la parte restante del conjunto de entrenamiento. De manera más rigurosa, asignamos a cada modelo la media, para las $r$ particiones, del error que tiene al predecir el target de la observación $\theta_{ival}$ cuando se entrena con $\theta_{itrain}$:

\begin{equation}
    VC(G, \{\theta_1, \theta_2, \ldots, \theta_r\})
    = \frac 1 r \sum_{i=1}^r \big ( G(\theta_{itrain}, \pi_X(\theta_{ival})) - \pi_Y(\theta_{ival}) \big )^2
\end{equation}


\paragraph{} Nos quedamos con los parámetros del modelo que menor puntuación obtenga.

\paragraph{} En ocasiones, trabajar con particiones leave-one-out tiene un coste temporal demasiado alto. En estos casos es una buena alternativa particionar según el "Método de agrupamiento para el manejo de datos" (siglas en inglés GMDH), donde la cantidad de particiones, $r$, ya no es $\#(D_{train})$, sino algún divisor. Si tomamos $m = \#(D_{train})$, tendremos:

\begin{enumerate}
    \item $\#(\theta_{itrain}) = \frac{m}{r}$.
    \item $\theta_{itrain} \bigcap \theta_{jtrain} = \{\emptyset\}$ siempre que $i \neq j$.
\end{enumerate}

\chapter{Modelos de regresión}\label{chap2}

\section{Regresión regularizada}

\paragraph{} La regresión regularizada es un modelo de regresión muy similar al de regresión multilineal, en el que penalizamos los coeficientes de las variables independientes $\beta_1, \beta_2, \ldots, \beta_n$. Escribimos una nueva función de error $\widetilde J$, y vemos su relación con la función de error de la regresión multilineal $J$:

\begin{equation}
    \widetilde J(\hat{\beta_0}, \hat{\beta_1}, \ldots, \hat{\beta_p})
    = \sum_{i=1}^{n} (Y_i - \hat{\beta}_0 - \sum_{i=1}^p \hat{\beta}_iX_i)^2 + \lambda \sum_{j=1}^{p} \hat{\beta}_{j}^{2}
    = J(\hat{\beta_0}, \hat{\beta_1}, \ldots, \hat{\beta_p}) + \lambda \sum_{j=1}^{p} \hat{\beta}_{j}^{2}
    .
\end{equation}

El hiperparámetro $\lambda$ balancea la importancia relativa de minimizar el error cuadrático y de minimizar los coeficientes. Según el valor de lambda, minimizaremos una función u otra, con lo que las soluciones serán distintas.

\paragraph{} Es importante notar que la penalización no se aplica sobre $\hat \beta_0$, que es simplemente la media de la variable respuesta cuando todas las variables independientes tienen valor 0.

\paragraph{} Normalmente, en problemas que tengan una relación casi lineal entre las variables independientes y la variable respuesta, la regresión multilineal suele tener poco sesgo y varianza relativamente alta. Esto significa que un cambio pequeño en los datos puede provocar una gran diferencia en la estimación de los coeficientes. Cuanto mayor sea la cantidad de variables, $p$, con respecto a la cantidad de datos, $n$, mayor será esta diferencia.

\paragraph{} Por último, el coste computacional de la regresión regularizada es prácticamente el mismo que el de la regresión multilineal, con lo que es difícil encontrar un problema en que la regresión multilineal sea más conveniente que la regresión regularizada.


\section{Perceptrón multicapa}

\paragraph{} En ésta sección veremos las redes neuronales multilineales, que llegan a dónde las redes neuronales sin capa oculta se quedan cortas, permitiéndonos resolver problemas no lineales.

\paragraph{} Una red neuronal consiste en capas con neuronas, donde cada neurona es una función no lineal que recibe una suma ponderada de las salidas de las neuronas de la capa anterior o de los atributos de la observación, y cuya salida es a su vez parte de la suma ponderada que será la entrada de las neuronas de la siguiente capa. La clave de estos modelos es que admiten unos algoritmos relativamente simples, en los que la función no lineal se puede aprender a partir del conjunto de datos.

\paragraph{} Uno de los métodos más conocidos para entrenar una red neuronal multilineal es el retropropagación, que estudiamos en cierta profundidad, ya que es un método potente y útil a la vez que relativamente simple, y dará pie a entender otros métodos más complicados como modificaciones de éste.

\paragraph{} Vamos a ver que cada problema tiene una arquitectura o topología de red neuronal multilineal propia, y aquí es donde entra en juego el conocimiento que tengamos sobre el dominio del problema: incluso las ideas más informales o heurísticas pueden incorporarse fácilmente a nuestro modelo, modificando el número de capas ocultas y el número de neuronas de cada una de ellas. La simplicidad del método de retropropagación permiten probar distintas alternativas, sin que esto suponga un gran trabajo.

\paragraph{} Una de las mayores dificultades a la hora de utilizar redes neuronales es ajustar su complejidad, es decir, seleccionar el modelo. Si la red tiene demasiadas capas ocultas con muchas neuronas, el modelo tendrá sobreajuste, mientras que si no tiene suficientes, generalizará demasiado, es decir, tendrá subajuste.

\paragraph{} Antes de empezar a definir las redes neuronales formalmente, hacemos hincapié en que como con cualquier modelo, las técnicas que veremos para redes neuronales no eximen de adquirir un conocimiento profundo del problema.







\subsection{Estructura y alcance de las redes neuronales}

\paragraph{} Las redes neuronales que vamos a estudiar tienen capa de entrada, capa oculta y capa de salida. Normalmente la cantidad de neuronas de la capa de entrada y de la de salida se obtiene directamente del problema, según la cantidad de atributos de cada dato y la cantidad de variables respuesta. La cantidad de neuronas de la capa oculta en cambio deberá calcularla el diseñador.

\paragraph{} Las neuronas se conectan por pesos. El sesgo se incluye como una neurona más que se conecta a todas las demás excepto a las de la capa de entrada, que emite un valor constante y no tiene entradas.

\paragraph{} La observación se introduce en la primera capa, recibiendo cada neurona el valor de un atributo de la observación. Las neuronas de esta capa transmiten el valor de su entrada a su salida sin modificarlo, es decir, su función es la función identidad.

\paragraph{} Las redes neuronales que estudiaremos y utilizaremos tendrán dos funciones: las neuronas de la capa de entrada y de la capa de salida, tendrán la función identidad, y las neuronas de la capa oculta tendrán una función definida a trozos conocida como rectificador o \textit{ReLU}:

\begin{equation}
    f(x)
    = \max\{x, 0\}
    =
    \left\{
    \begin{array}{lcc}
    x &   \text{si \ }  x \geq 0 \\
    \\0 &   \text{si \ } x < 0
    \end{array}
    \right.
    .
\end{equation}

La entrada de las neuronas, es decir, de sus funciones, será una combinación lineal de las salidas de las neuronas de la capa anterior y la neurona del sesgo, a excepción de las neuronas de la capa de entrada. En estas últimas, la entrada de la neurona $i$ es el valor del atributo $i$ de la observación.

\paragraph{} Llamaremos $x_i$ a la salida de las neuronas de la primera capa, $y_j$ a las de la capa oculta, y $z_k$ a las de la capa de salida. Decimos además
\[\boldsymbol{x} = (x_1, \ldots, x_{n_1}),\]
\[\boldsymbol{y} = (y_1, \ldots, y_{n_2}),\]
\[\boldsymbol{z} = (z_1, \ldots, z_{n_3}),\]

\begin{equation}
    z_k(\boldsymbol{y}) = f\bigg(\sum_{j=0}^{n_2} w_{kj} y_j\bigg)
    ,
\end{equation}
%
donde $w_{kj}$ son los pesos que unen las neuronas de la capa oculta con la neurona k de la capa de salida. Además, sabemos que la salida de cada neurona de la capa oculta es 

\begin{equation}
    y_j(\boldsymbol{x}) = f\bigg(\sum_{i=0}^{n_1} w_{ji} x_i\bigg)
    .
\end{equation}

Con $w_{ji}$ los pesos que unen las neuronas de la capa de entrada con la neurona j de la capa oculta, análogamente al caso anterior. Sustituyendo obtenemos la salida de la red neuronal en función de la entrada:

\begin{equation}
    z_k(\boldsymbol{x}) = f\bigg(\sum_{j=0}^{n_2} w_{kj} f\bigg(\sum_{i=0}^{n_1} w_{ji} x_i\bigg)\bigg)
    .
\end{equation}

\subsubsection{¿Qué funciones puede representar una red neuronal?}

\paragraph{} El teorema de Kolmogorov demuestra que cualquier función continua $g(x)$ cuyo dominio esté restringido a un hipercubo $I^n : I = [0, 1], n \geq 2$ puede expresarse en la forma 

\begin{equation}
    g(x) = \sum_{j=1}^{2n+1} \Xi_j ( \sum_{i=1}^d \Psi_{ij}( x_i ) )
\end{equation}

para funciones $\Xi_j$ y $\Psi_{ij}$ adecuadas.

\paragraph{} Este teorema nos permite asegurar que cualquier función continua puede expresarse en una red neuronal de 3 capas, si ponemos $2n+1$ neuronas ocultas, cada una con una función $\Xi_j$, y teniendo en cada una de las neuronas de la capa de entrada, que deberán ser $d(2n+1)$, una función $\Psi_{ij}$. En la última capa habría una única neurona que sumaría las salidas de todas las neuronas ocultas.

\paragraph{} Otra prueba del alcance de las redes neuronales es el teorema de Fourier, que dice que cualquier función continua puede aproximarse arbitrariamente cerca por una suma de funciones armónicas, posiblemente infinita.

\paragraph{} Esto sería una red neuronal con la función identidad en las neuronas de la capa de entrada, una cantidad posiblemente muy grande de neuronas en la capa oculta, con dichas funciones armónicas, y una sola neurona en la capa de salida, con una función que sume las salidas de las funciones de la capa oculta.

\paragraph{} Sabemos que un conjunto completo de funciones, por ejemplo los polinomios, pueden representar cualquier función, sin embargo, esto también puede conseguirse utilizando una sola función, siempre que utilicemos los parámetros adecuados. Esto es lo que queremos conseguir con las redes neuronales multilineales, cuyas neuronas siempre tendrán la misma función de transferencia.

\paragraph{} Ninguno de los teoremas anteriores nos da ninguna pista sobre la cantidad de neuronas ocultas ni sobre los pesos correctos. Además, aunque existiese, una prueba constructiva nos sería de poca ayuda, ya que normalmente no sabremos cómo es la función buscada. Sin embargo, estos resultados nos ayudan a pensar que el esfuerzo en esta búsqueda es razonable.



\subsection{Algoritmo de retropropagación}

\paragraph{} Las redes neuronales tienen dos modos de funcionamiento: feedforward y aprendizaje. El feedforward consiste en introducir una observación en la capa de entrada para obtener un resultado por la capa de salida, mientras que aprendizaje (supervisado) consiste en introducir una observación en la capa de entrada pero conociendo el resultado correcto, y según sea el producido por la red, ajustar los pesos para que se parezcan lo máximo posible.

\paragraph{} Sin embargo, no sabemos cómo modificar los pesos de la capa de entrada a la oculta, ya que no sabemos que salidas deberíamos estar obteniendo por las neuronas de esta capa. Éste es el problema de asignación de crédito (credit assignment problem). El algoritmo de retropropagación es una solución.

\subsubsection{Aprendizaje de la red}

\paragraph{} Queremos medir la distancia entre cada predicción y el resultado real, así que utilizamos el error cuadrático. Si fijamos el valor de entrada, el error cuadrático se puede ver como una función de todos los pesos de la red. La llamamos $J(\textbf{w})$ (multiplicamos por $\frac{1}{2}$ para derivar más cómodamente):

\begin{equation}
    \label{eq_Jw}
    J(\textbf{w}) = \frac{1}{2} \sum_{k=1}^{n_3} (t_k - z_k)^2 = \frac{1}{2} (\textbf{t} - \textbf{z})^2
    ,
\end{equation}

siendo \textbf{t} y \textbf{z} son los vectores esperado (target) y obtenido, y \textbf{w} el vector de todos los pesos de la red (weight). Notar que en este sumatorio ya no incluimos la neurona del sesgo, por lo que empezamos a sumar en $k=1$. Queremos minimizar esta función; encontrar los pesos para los que la diferencia entre el valor predicho y el valor poblacional es mínima.

\paragraph{} El algoritmo de retropropagación consiste en intentar llegar a un mínimo local de $J(\textbf{w})$ haciendo pequeñas modificaciones de  $\textbf{w}$ en la dirección contraria a la del vector gradiente en ese punto, que es aquella en la que más rápido decrece la imagen.

\paragraph{} Las modificaciones serán proporcionales al error cuadrático, pues si este es cercano a cero, ya estamos muy cerca del mínimo (que como mucho, será 0). Representamos el incremento de $\textbf{w}$ así:

\begin{equation}
    \Delta \textbf{w} = - \eta \frac{\partial J}{\partial \textbf{w}}
\end{equation}

o, componente a componente:

\begin{equation}
    \Delta w_{mn} = - \eta \frac{\partial J}{\partial w_{mn}}
    ,
\end{equation}

donde $\eta$ indica el tamaño del incremento.

\paragraph{} Primero vamos a calcular el incremento para los pesos de entre la capa oculta y la de salida, y luego para los pesos de entre la capa de entrada y la oculta. Llamamos $net_k$ a la entrada de la neurona k de la capa de salida, y $net_j$ a la entrada de la neurona j de la capa oculta:

\begin{multicols}{2}
  \begin{equation}\label{eqn:netk}
    net_k = \sum_{j=0}^{n_2} w_{kj}y_j
  \end{equation}\break
  \begin{equation}\label{eqn:netj}
    net_j = \sum_{i=0}^{n_1} w_{ji}x_j
  \end{equation}
\end{multicols}

\paragraph{} Comenzamos a desarrollar la derivada de $J$ respecto del peso $w_{kj}$:

\begin{equation}
    \frac{ \partial J } { \partial w_{kj} }
    = \frac{ \partial J } { \partial net_k } \frac{ \partial net_k } {        \partial w_{kj}}
    ,
\end{equation}

y definimos la sensibilidad de la neurona k de la capa oculta como

\begin{equation}
    \delta_k
    = - \frac{ \partial J } { \partial net_k }
    = - \frac{ \partial J } { \partial z_k } \frac{ \partial z_k } {         \partial net_k}
    = (t_k - z_k) f'(net_k)
    .
\end{equation}

Luego, derivando respecto de $w_{kj}$ en la ecuación \ref{eqn:netk}, obtenemos

\begin{equation}
    \label{eq_net_k}
    \frac { \partial net_k } { \partial w_{kj} } = y_j
    .
\end{equation}

Finalmente, sustituimos en la ecuación del incremento de $w_{kj}$:

\[
    \Delta w_{kj}
    = - \eta \frac{\partial J}{\partial w_{kj}} 
    = - \eta \frac{ \partial J } { \partial z_k } \frac{ \partial z_k } { \partial net_k} \frac{ \partial net_k } { \partial w_{kj}}
\]

\begin{equation}
    \boxed{ 
        \Delta w_{kj} = \eta  \delta_k y_j = \eta (t_k - z_k) f'(net_k) y_j 
    }
    \;.
\end{equation}

\paragraph{} Ahora hacemos lo mismo, con algún paso más, para los pesos de la capa de entrada a la capa oculta:
\[ 
    \frac { \partial J } { \partial w_{ji} }
    = \frac { \partial J } { \partial y_j } \frac { \partial y_j } { \partial net_j } \frac { \partial net_j } { \partial w_{ji} }
    = \frac { \partial J } { \partial y_j } f'(net_j) \frac { \partial net_j } { \partial w_{ji} }
    .
\]

Desarrollamos el primer término:

\[
    \begin{split} 
        \frac { \partial J } { \partial y_j }
        = \bigg( \frac { \partial } { \partial y_j } \bigg) \bigg( \frac{1}{2} \sum_{k=1}^{n_3} (t_k - z_k)^2 \bigg)
        = - \sum_{k=1}^{n_3} (t_k - z_k) \frac { \partial z_k } { \partial y_j } 
        = \\
        = - \sum_{k=1}^{n_3} (t_k - z_k) \frac { \partial z_k } { \partial net_k } \frac { \partial net_k } { \partial y_j }
        = - \sum_{k=1}^{n_3} (t_k - z_k) f'(net_k) \frac { \partial net_k } { \partial y_j }
    .
    \end{split}
\]

Ahora derivamos respecto de $y_j$ en la ecuación \ref{eqn:netk}, obteniendo

\begin{equation}
    \frac { \partial J } { \partial y_j }
    = - \sum_{k=1}^{n_3} (t_k - z_k) f'(net_k) w_{kj}
    .
\end{equation}

De manera análoga a como se hizo antes, definimos la sensibilidad de una neurona oculta como
\begin{equation}
    \delta_j = f'(net_j) \sum_{k=1}^{n_3} w_{kj}\delta_k =  
    f'(net_j) \sum_{k=1}^{n_3} w_{kj} (t_k - z_k) f'(net_k)
    \; .
\end{equation}

Además, derivando respecto de $w_{ji}$ en la ecuación de $net_j$ (ecuación \ref{eqn:netj}), obtenemos 

\begin{equation}
    \frac { \partial net_j } { \partial w_{ji} } = x_i
    \; ,
\end{equation}
%
y haciendo todas estas sustituciones en la ecuación incremento de $w_{ji}$ nos queda
 
\[
    \Delta w_{ji}
    = - \eta \frac { \partial J } { \partial y_j } \frac { \partial y_j } { \partial net_j } \frac { \partial net_j } { \partial w_{ji} }
\]

\begin{equation}
    \boxed{
        \Delta w_{ji} = \eta \bigg( \sum_{k=1}^{n_3} (t_k - z_k) f'(net_k) w_{jk} \bigg) f'(net_j) x_i
    }
    \; .
\end{equation}

o, en su forma compacta utilizando las sensibilidades que hemos definido,

\[
    \Delta w_{ji} = \eta \bigg( \sum_{k=1}^{n_3} \delta_k w_{jk} \bigg) f'(net_j) x_i
\]

\[
    \Delta w_{ji} = \eta \delta_j x_i
\]





























\section{Máquinas de vectores soporte de regresión (SVR)}

\paragraph{} Las máquinas de vectores soporte de regresión (siglas en inglés SVR) son una solución al problema de regresión que consiste en una función $f(\boldsymbol x)$ que, en las observaciones del conjunto de aprendizaje, tenga un error menor que un $\varepsilon$ definido, y que al mismo tiempo sea lo más plana posible. En este contexto, que una función sea plana significa que sea lo más parecida posible a una función constante.

\paragraph{} Conocemos un conjunto de datos $D_n$ como en la definición \ref{D_n}. A partir de estos datos construiremos $f$.

\paragraph{} Estudiaremos primero el caso en que $f$ es lineal, y por tanto, tiene la forma 
\begin{equation}
    f(\boldsymbol x)
    = \langle \boldsymbol w, \boldsymbol x \rangle + b
    \;\;\;\; : \boldsymbol w \in \mathbb{R}^p, b \in \mathbb{R}
    .
\end{equation}
%
En este caso, donde, sea cual sea f, su segunda derivada será $0$, que sea plana lo entendemos como que $\|w\|$ sea cercano a $0$. Encontrar la $f$ entonces sería resolver el siguiente problema de optimización:
\begin{equation}
    \operatorname{min} \quad \frac{1}{2}\|w\|^{2}
    \;\; : \;\;
    \left\{
        \begin{array}
            {l}
            y_i -\langle w, x_i \rangle -b \leq \varepsilon \\
            \langle w, x_i\rangle+b-y_i \leq \varepsilon
        \end{array}
    \right.
    .
\end{equation}

\paragraph{} Esta $f$ siempre existe ya que es la solución de un problema de optimización convexa.

\paragraph{} En ocasiones queremos permitir cierta cantidad de error, que se traduce en introducir las llamadas \textit{slack variables}, $\xi_i, \xi_i^*$:

\begin{equation}\label{eqn:optSVR}
    \operatorname{min} \quad \frac{1}{2}\|w\|^{2} + C \sum_{i=1}^n (\xi_i + \xi_i^*)
    \;\; : \;\;
    \left\{
        \begin{array}
            {l}
            y_i -\langle w, x_i \rangle -b \leq \varepsilon + \xi_i\\
            \langle w, x_i\rangle+b-y_i \leq \varepsilon + \xi_i^*
        \end{array}
    \right.
    .
\end{equation}

\paragraph{} La constante $C$ balancea la importancia de que $f$ sea plana y la cantidad hasta la que toleramos desviaciones mayores que $\varepsilon$. Es importante el detalle de que sólo las desviaciones mayores que $\varepsilon$ tienen coste. 

\paragraph{} En la mayoría de los casos, resultará más sencillo, y es lo que haremos, resolver la ecuación \ref{eqn:optSVR} en su expresión dual.

\paragraph{} Construimos el problema dual hallando el máximo de la función en lugar del mínimo, invirtiendo las inecuaciones y añadiendo el conjunto dual de variables, que son los multiplicadores de Langrange $\eta_i^{(*)}$ y $\alpha_i^{(*)}$:

\begin{equation}\label{eqn:probDual}
    \begin{aligned}
        L:=& \frac{1}{2}\|\boldsymbol w\|^{2}+C \sum_{i=1}^{n}(\xi_i+\xi_i^*)-\sum_{i=1}^{n}(\eta_i \xi_i+\eta_i^* \xi_i^*) \\
        &-\sum_{i=1}^{n} \alpha_i(\varepsilon+\xi_i-y_i+\langle \boldsymbol w, \boldsymbol{x_i}\rangle+b) \\
        &-\sum_{i=1}^{n} \alpha_i^*(\varepsilon+\xi_i^*+y_i-\langle \boldsymbol w, \boldsymbol{x_i}\rangle-b)
    \end{aligned}
    .
\end{equation}

\paragraph{} Ahora derivando respecto de las variables primarias $\boldsymbol w$, $b$ y $\xi_i^{(*)}$ y anulando, obtenemos el mínimo:

\begin{equation}\label{eqn:optDualB}
    \partial_{b} L =\sum_{i=1}^{n}(\alpha_i^{*}-\alpha_i)=0
    ,
\end{equation}

\begin{equation}\label{eqn:optDualW}
    \partial_{\boldsymbol w} L =\boldsymbol w-\sum_{i=1}^{n}(\alpha_i-\alpha_i^{*}) \boldsymbol{x_i}=0
    ,
\end{equation}

\begin{equation}\label{eqn:optDualXi}
    \partial_{\xi_i^{(*)}} L =C-\alpha_i^{(*)}-\eta_i^{(*)}=0
    .
\end{equation}

\paragraph{} Sustituyendo las ecuaciones \ref{eqn:optDualB}, \ref{eqn:optDualW} y \ref{eqn:optDualXi} en \ref{eqn:probDual}, obtenemos el problema de optimización dual

\begin{equation}\label{eqn:optDual}
    \begin{array}{l}
        \max
        \left\{
            \begin{aligned}
                -\frac 1 2 \sum_{i, j=1}^n(\alpha_i-\alpha_i^*)(\alpha_j-\alpha_j^*)\langle \boldsymbol{x_i}, \boldsymbol{x_j}\rangle \\
                -\varepsilon \sum_{i=1}^n(\alpha_i+\alpha_i^*)+\sum_{i=1}^n y_i(\alpha_i-\alpha_i^*)
            \end{aligned}
        \right.\\
        \;\; : \;\; \sum_{i=1}^n(\alpha_i-\alpha_i^*)=0 \quad \text{ y } \quad \alpha_i, \alpha_i^* \in[0, C]
    \end{array}
    ,
\end{equation}
%
donde hemos eliminado las variables $\eta_i^{(*)}$ despejando en la ecuación \ref{eqn:optDualXi}. 

\paragraph{} A partir de la ecuación \ref{eqn:optDualW}, podemos despejar $\boldsymbol w$ y que quede expresado en función de los $\boldsymbol{x_i}$ por un coeficiente:

\begin{equation}
    \boldsymbol w = \sum_{i=1}^n(\alpha_i-\alpha_i^*)\boldsymbol{x_i}
    ,
\end{equation}
%
y por tanto
\begin{equation}
    f(\boldsymbol x)
    = \sum_{i=1}^n(\alpha_i-\alpha_i^*) \langle x_i, \boldsymbol x \rangle + b
    .
\end{equation}

\paragraph{} Vemos que $\boldsymbol w$ puede expresarse como una combinación lineal de las observaciones $\boldsymbol{x_i}$. Además, el algoritmo consiste únicamente en hacer productos escalares entre observaciones.

\paragraph{} Ahora falta calcular b, para lo que utilizaremos las condiciones de Karush-Kuhn-Tucker, que dicen que la solución de nuestro problema también es solución de las siguientes cuatro ecuaciones:
\begin{equation}\label{eqn:KKK1}
    \alpha_i(\varepsilon+\xi_i-y_i+\langle \boldsymbol w, \boldsymbol{x_i}\rangle+b)=0
    ,
\end{equation}
\begin{equation}\label{eqn:KKK2}
    \alpha_i^*(\varepsilon+\xi_i^*+y_i-\langle \boldsymbol w, \boldsymbol{x_i}\rangle-b)=0
    ,
\end{equation}
\begin{equation}
    (C-\alpha_i) \xi_i=0
\end{equation}
%
y
\begin{equation}
    (C-\alpha_i^*) \xi_i^*=0
    .
\end{equation}

\paragraph{} Antes de hablar de $b$, nos fijamos en las implicaciones de estas condiciones, pues hay que hacer unas cuantas observaciones muy importantes. Lo primero es que si una observación $i$ sale del tubo épsilon, entonces o $\xi_i$ o $\xi^*_i$ son distintos de cero. Digamos que $\xi_i$ es distinto de cero y el otro caso es análogo, intercambiando el $*$. Entonces, $\xi_i^*$ es $0$, puesto que es parte de lo que queremos minimizar y no hay ninguna otra restricción por la que tenga que ser mayor que $0$.

\paragraph{} Como $\xi_i$ no es cero, para que se cumpla la tercera condición, tiene que cumplirse $\alpha_i = C$. Además, al ser $\xi_i$ distinto de cero, la primera condición se cumple porque se anula el segundo término, pero la segunda tiene el segundo término no nulo, con lo cual $\alpha_i^* = 0$ para que sea cierta. De esta forma, para todas las observaciones cuya predicción salga del tubo épsilon, sabemos que $\alpha_i\alpha_i^*=0$ y que o $\alpha$ o $\alpha^*$ es igual a $C$.

\paragraph{} En el caso de que $|y_i - \langle \boldsymbol w, \boldsymbol x_i \rangle - b| < \varepsilon$, para que se cumplan las dos primeras condiciones, es necesario que $\alpha^{(*)}=0$.

\paragraph{} Lo que concluimos de estas observaciones es que para escribir $\boldsymbol w$ solo nos hace falta conocer las observaciones $\boldsymbol x_i$ cuya imagen por $f$ salga del tubo épsilon, ya que todas las demás observaciones se multiplican por un coeficiente igual a cero. A las observaciones con coeficiente no nulo las denominamos vectores soporte.


\paragraph{} Volviendo al cálculo de $b$, podemos  escribir
\begin{equation}
    \begin{array}{llll}
        \varepsilon-y_i+\langle \boldsymbol w, \boldsymbol{x_i}\rangle+b \geq 0 \;\; \text { y } \;\; \xi_i=0 &\text { si } \alpha_i<C \\
        \varepsilon-y_i+\langle \boldsymbol w, \boldsymbol{x_i}\rangle+b \leq 0 &\text { si } \alpha_i>0
    \end{array}
    .
\end{equation}

\paragraph{} Haciendo el estudio análogo sobre $\alpha_i^*$, obtenemos

\begin{equation}
    \begin{array}{l}
    \max \{-\varepsilon+y_{i}-\langle w, x_{i}\rangle \mid \alpha_{i}<C \text { o } \alpha_{i}^{*}>0\} \leq b \leq \\
    \min \{-\varepsilon+y_{i}-\langle w, x_{i}\rangle \mid \alpha_{i}>0 \text { o } \alpha_{i}^{*}<C\}
\end{array}
,
\end{equation}
%
y si algún $\alpha_i^{(*)} \in (0, C)$, tanto el máximo como el mínimo son $b$.


\subsubsection*{Funciones kernel}

\paragraph{} El siguiente paso es conseguir que el algoritmo de SVR sea no lineal. En principio podríamos conseguirlo simplemente aplicando a los datos una función no lineal $\phi: \mathcal{X} \to \mathcal{F}$ y luego aplicar el algoritmo como lo hemos descrito hasta ahora. El problema es que aplicar una función $\phi$ directamente a todos los datos tiene un coste computacional demasiado alto para problemas que a día de hoy son comunes.

\paragraph{} La solución es que en lugar de calcular la imagen por $\phi$ de todos los datos de la muestra, aplicaremos la función no lineal de forma implícita. El detalle gracias al cual podemos hacer esto es que en ningún momento nos hace falta conocer $\phi(\boldsymbol{x_i})$ y $\phi(\boldsymbol{x_j})$ individualmente, sino que con conocer $\langle \phi(\boldsymbol{x_i}), \phi(\boldsymbol{x_i}) \rangle$ nos basta. De esta forma, utilizaremos ciertas funciones $K: \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}$ que son iguales a este producto escalar, para alguna $\phi$ no lineal, es decir, que se cumple $K(\boldsymbol{x_i}, \boldsymbol{x_j}) = \langle \phi(\boldsymbol{x_i}), \phi(\boldsymbol{x_i}) \rangle$.

\paragraph{} Entonces, en problemas no lineales tenemos que resolver una versión de \ref{eqn:optDual} modificada, en la que cambiamos $x$ por $\phi(x)$, es decir, $\langle \boldsymbol{x_i}, \boldsymbol{x_j} \rangle$ por $K(\boldsymbol{x_i}, \boldsymbol{x_j})$:

\begin{equation}
    \begin{array}{l}
        \max
        \left\{
            \begin{aligned}
                -\frac 1 2 \sum_{i, j=1}^n(\alpha_i-\alpha_i^*)(\alpha_j-\alpha_j^*) K(\boldsymbol{x_i}, \boldsymbol{x_j}) \\
                -\varepsilon \sum_{i=1}^n(\alpha_i+\alpha_i^*)+\sum_{i=1}^n y_i(\alpha_i-\alpha_i^*)
            \end{aligned}
        \right.\\
        \;\; : \;\; \sum_{i=1}^n(\alpha_i-\alpha_i^*)=0 \quad \text{ y } \quad \alpha_i, \alpha_i^* \in[0, C]
    \end{array}
    .
\end{equation}

\paragraph{} Además, tendremos
\begin{equation}
        \boldsymbol w = \sum_{i=1}^n(\alpha_i-\alpha_i^*)\phi(\boldsymbol{x_i}),
\end{equation}
%
aunque nunca calcularemos su valor explícitamente, sino que hallaremos $f(\boldsymbol{x_j})$ como
\begin{equation}
        f(\boldsymbol x)
    = \sum_{i=1}^n(\alpha_i-\alpha_i^*) K(\boldsymbol{x_i}, \boldsymbol{x_j}) + b
    .
\end{equation}

\paragraph{} Ahora buscamos la función más plana posible en el espacio aumentado, no en el espacio de atributos.

\paragraph{} Algunos ejemplos de funciones kernel son

\begin{equation}
    K(\boldsymbol x, \boldsymbol{x'}) = (\langle \boldsymbol x, \boldsymbol{x'} \rangle + c)^p  \;\; : p \in \mathbb{N}, c \geq 0
    ,
\end{equation}
\begin{equation}
    K(\boldsymbol x, \boldsymbol{x'}) = \widetilde{K}(\boldsymbol x - \boldsymbol{x'}) = e^{-\frac{\|\boldsymbol x - \boldsymbol{x'}\|^2}{2\sigma^2}}
    ,
\end{equation}
%
donde la función $K(\boldsymbol x, \boldsymbol{x'})$ puede expresarse en términos de la diferencia entre $\boldsymbol x$ y $\boldsymbol{x'}$ mediante otra función $\widetilde{K}$, y $\sigma$ es la norma de la desviación típica de la variable $X$.




































\chapter{Modelos de ensemble}\label{chap3}





\section{¿Qué es un modelo de ensemble?}

\paragraph{} Los métodos de ensemble de regresión son un tipo de modelo de regresión compuesto de varios modelos individuales, que se entrenan para resolver el mismo problema y son combinados para obtener mejores resultados.

\paragraph{} Utilizaremos el término modelo individual para hacer referencia a un modelo tradicional que no está compuesto por otros modelos, en contraste con un modelo de ensemble, que sí estará compuesto por otros modelos; de hecho, por modelos individuales.

\paragraph{} La solución ideal al problema de regresión sería un modelo que tuviese suficientes grados de libertad como para resolver la complejidad subyacente de los datos, pero no demasiados para que no sobreajuste.

\paragraph{} El rendimiento de los modelos que sobreajustan suele variar mucho según la forma de los datos sobre los que se hagan predicciones, es decir, tienen varianza alta, y esto es algo no deseable.

\paragraph{} Los modelos individuales pueden combinarse entre sí para formar modelos más complejos, que serán los modelos de ensemble. A menudo tenemos modelos individuales que no dan muy buenos resultados por tener mucho sesgo (no tienen suficientes grados de libertad), o que por el contrario tienen demasiada varianza (demasiados grados de libertada). Los métodos de ensemble construyen un método con menor sesgo o menor varianza que obtenga mejores resultados.


\paragraph{} Un modelo de ensemble es un modelo que hace predicciones basadas en las predicciones de ciertos modelos individuales. El primer paso para construir un modelo de ensemble es seleccionar los modelos base que vamos a utilizar. La mayoría de las veces (bagging, boosting) utilizaremos un único modelo y variaremos los parámetros y/o el conjunto de aprendizaje. Entonces decimos que el método de ensemble es homogéneo. En los modelos de ensemble stacking en cambio se utilizan distintos modelos individuales, cosa que puede tener grandes beneficios. Entonces decimos que el modelo de ensemble es heterogéneo.

\subsection*{Bagging}

\paragraph{} Para definir bagging antes es necesario definir el bootstrapping, que es un método de remuestreo en el que generamos muestras de tamaño $k$ a partir de un conjunto de datos de tamaño $n$, haciendo extracciones aleatorias con reemplazo. Este método tiene la ventaja de que, bajo las hipótesis de representatividad e independencia, podemos considerar que las extracciones se hacen directamente de la distribución subyacente.

\paragraph{} La hipótesis de representatividad consiste en asumir que $n$ es lo suficientemente grande como para reflejar la complejidad de la distribución subyacente.

\paragraph{} La hipótesis de independencia consiste en asumir que $n$ es lo suficientemente grande en comparación con $k$ como para poder asumir que las muestras no tendrán correlación. Podremos considerar las observaciones casi independientes idénticamente distribuidas.
    

    
\paragraph{} Bagging es un método de ensemble que consiste en entrenar varios modelos individuales independientes y promediar sus predicciones para obtener un modelo con menos varianza. Al entrenarse los modelos individuales de manera independiente, tenemos la posibilidad de entrenarlos en paralelo, cosa que puede suponer un ahorro muy significativo de tiempo.

\paragraph{} El procedimiento consiste en extraer una muestra bootstrap para cada modelo, que será su conjunto de aprendizaje. La predicción del modelo bagging se obtiene haciendo un promedio entre las predicciones de los modelos individuales.
    
\paragraph{} Hacer un promedio de las predicciones de los modelos individuales no cambia la respuesta esperada, pero reduce la varianza, de la misma manera que hacer la media de variables aleatorias i.i.d. preserva el valor esperado pero reduce la varianza.


\paragraph{} Random forests es el ejemplo más conocido de modelo de ensemble bagging, donde se combinan árboles de decisión.

\subsection*{Boosting}

\paragraph{} Boosting es un método de ensemble que consiste en entrenar varios modelos individuales secuencialmente, influyendo el entrenamiento de un modelo en el de los modelos posteriores. Conseguimos un modelo con menor sesgo, aunque en ocasiones el coste temporal es muy elevado.

\paragraph{} Para que el coste temporal sea razonable, se suelen utilizar modelos individuales poco precisos que se entrenen rápidamente. Cada modelo se entrena dando más prioridad a las observaciones que han sido mal clasificadas previamente.

\paragraph{} La predicción del modelo de ensemble bagging será una suma ponderada de las predicciones de los modelos individuales. Normalmente buscar una ponderación que dé buenos resultados no es inmediato.

\paragraph{} \textit{Adaptative boosting} y \textit{gradient boosting} son dos maneras distintas de construir un modelo de ensemble bagging, que se diferencian en la manera de encontrar los coeficientes de la suma ponderada.


\subsection*{Stacking}

\paragraph{} Stacking es un método de ensemble que consiste en entrenar varios modelos individuales que pueden ser heterogéneos. Este es el modelo que empleamos en los experimentos, así que le dedicaremos más tiempo en la siguiente parte de este trabajo.


















\section{Modelo de ensemble \textit{stacking}}

\paragraph{} En esta sección vamos a definir una técnica utilizada para construir métodos de ensemble conocida como \textit{stacking} o \textit{stacked generalization}.

\paragraph{} Los modelos de ensemble dan una solución más elaborada que la de otros métodos al problema de elegir con qué modelos de regresión individuales haremos predicciones, de entre una familia de N modelos $\{G_j\}$, con $N \geq 1$.

\paragraph{} En validación cruzada, por ejemplo, que es una solución muy popular a este problema, nos quedamos con un único modelo que consideramos el mejor, es decir, que ha obtenido la mejor puntuación según una métrica que hemos definido. Esto es una solución relativamente simple y de bajo coste, pero tiene la desventaja de que descartamos todos los modelos menos uno, desentendiéndonos de cualquier aportación que pudiesen hacer.

\paragraph{} Al trabajar con modelos de ensemble, en cambio, involucramos a la familia completa de modelos de regresión individuales, $\{G_j\}$, obteniendo así un modelo más potente. La idea subyacente es que los fallos de cada modelo se compensen con los demás, ya que la porción de datos donde un modelo comete mayor fallo no tiene por qué ser la misma que para otro modelo. Con cierta elección cuidadosa de los modelos individuales que compondrán nuestro modelo de ensemble, esperamos que no lo sean.

\paragraph{} A modo de adelanto para facilitar la comprensión del método stacking, damos la siguiente comparación entre el funcionamiento de un modelo individual y uno stacking: 

\paragraph{} Un modelo individual tradicional se entrena sobre un conjunto de datos que vive en un espacio, digamos el espacio de nivel 0, y luego es capaz de predecir el target de nuevas observaciones que también vivan en el espacio de nivel 0.

\paragraph{} Un modelo stacking que utilice un conjunto de N modelos de regresión individuales, hace una transformación de los datos del espacio de nivel 0 para conseguir datos en un espacio de nivel 1, transformación en la cual toma parte cierto subconjunto de los N modelos. A continuación, entrena un modelo sobre los datos de nivel 1, y éste es el que se utiliza para hacer predicciones. Como los datos sobre los que queremos hacer predicciones viven en el espacio de nivel 0, antes de predecir tendremos que llevar estos datos al nivel 1, aplicar el modelo, y finalmente tomar la predicción de nivel 1 que obtengamos y llevarla de vuelta al nivel 0.

\paragraph{} Llamaremos espacio de nivel 0 a $\mathbb{R}^d \times \mathbb{R}$, que es donde viven los elementos de $D_n$, y espacio de nivel 1 a $\mathbb{R}^k \times \mathbb{R}$. Puede haber espacios de otros niveles, aunque para esta definición solo nos hacen falta estos dos.

\paragraph{} Los elementos del espacio de nivel 1 también los escribimos con la forma habitual $(\boldsymbol{\widetilde{X}}_i, \widetilde{Y})$. Cada observación de este espacio se construye a partir k modelos de regresión individuales de nuestro conjunto $\{G_j\}$, fijando una partición $\theta_i$ y haciendo k predicciones $G_j(\theta_{itrain}, \pi_X(\theta_{ival}))$. Así obtenemos k valores, que serán la componente $\boldsymbol{\widetilde{X}}_i$ de nuestro elemento $(\boldsymbol{\widetilde{X}}_i, \widetilde{Y})$. 

\paragraph{} La manera de obtener $\widetilde{Y}$, es mediante una transformación biyectiva $\phi(Y)$. En nuestro caso, utilizaremos la identidad en $\mathbb{R}$, es decir, no modificaremos $Y$:
\begin{align}
    \begin{split}
        \phi: \mathbb{R} &\to \mathbb{R}\\
        Y_i &\mapsto Y_i
    \end{split}
    .
\end{align}

\paragraph{} Estos últimos párrafos se corresponden con la figura \ref{dibujoGeneralizador1}.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{dibujoGeneralizador1.png}
\caption{En esta imagen vemos como se genera una observación genérica $(\widetilde{\boldsymbol X}_i, \widetilde{Y}_i)$ del espacio de nivel 1, a partir de todo $D_{train}$ utilizando una partición $\theta_i$.}
\label{dibujoGeneralizador1}
\end{figure}

\paragraph{} Para $\theta_i$ fija, hemos obtenido un elemento del espacio de nivel 1, por lo que rotando $i$, en total obtendremos r elementos. Sobre este nuevo conjunto de entrenamiento, que podemos llamar conjunto de entrenamiento de nivel 1 o reducido, entrenaremos un último modelo de regresión individual $\widetilde{G} \in {G_j}$ de la manera habitual.

\paragraph{} Llegados a este punto ya sabemos construir el modelo final $\widetilde{G}$ que se ha entrenado sobre el conjunto de entrenamiento de nivel 1, y que por tanto predice sobre el espacio de nivel 1 (figura \ref{dibujoGeneralizador1}). Solo falta definir cómo llevar una observación a dicho nivel para predecir su target, y cómo traer esta predicción de vuelta al nivel 1.

\paragraph{} Digamos que $\boldsymbol X \in \mathbb{R}^d$ es una observación en el espacio de nivel 0 y $\widetilde{\boldsymbol X} \in \mathbb{R}^k$ su transformación al espacio de nivel 1. Entonces tenemos

\begin{equation}
    \widetilde{\boldsymbol X} = (G_1(D_n; (\boldsymbol X, 0)), G_2(D_n; (\boldsymbol X, 0)), \ldots, G_k(D_n; (\boldsymbol X, 0))) 
    ,
\end{equation}
%
es decir, siguiendo el mismo procedimiento que para obtener el conjunto de entrenamiento de nivel 1 o reducido, solo que esta vez entrenando los modelos $G_1, G_2, \ldots, G_k$ sobre toda la muestra $D_n$, en lugar de sobre un subconjunto de una de las particiones $\theta_i$. Sobre esta observación del espacio de nivel 1, $\widetilde{\boldsymbol X}$, ya podemos predecir con $\widetilde{G}$, para obtener $\widetilde{Y}$.

\paragraph{} Solo queda llevar $\widetilde{Y}$ del espacio de nivel 1 al espacio de nivel 0. Esto lo hacemos mediante la inversa de la aplicación que llevaba targets del nivel 0 al nivel 1, es decir, con $\phi^{-1}$. Recordando como habíamos definido $\phi$, tenemos
\begin{equation}
    \phi^{-1}(\widetilde{Y}) = \widetilde{Y}
    .
\end{equation}
%
Y de aquí obtenemos finalmente nuestra predicción (figuras \ref{dibujoGeneralizador2} y \ref{dibujoPrediccionGeneralizador}).

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{dibujoGeneralizador2.png}
    \caption{En esta imagen tenemos una visión general de un método de ensemble con stacking.}
    \label{dibujoGeneralizador2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{dibujoPrediccionGeneralizador.png}
    \caption{Esquema de una predicción utilizando un modelo de ensemble ya entrenado.}
    \label{dibujoPrediccionGeneralizador}
\end{figure}

\paragraph{} Este es el proceso completo, que puede iterarse para obtener p niveles, con $p \geq 1$.

\paragraph{} A día de hoy no hay reglas generales que indiquen qué generalizadores utilizar para cada nivel, ni con qué proceso obtener los k números a partir del conjunto de aprendizaje del nivel $i$ que formen las componentes de entrada del nivel $i+1$, etc. La manera de proceder habitualmente es aplicar conocimiento específico del problema para seleccionar estos hiperparámetros.












\chapter{Simulaciones y resultados}\label{chap4}

\section{Parque eólico experimental de Sotavento}

\section{Regresión regularizada}

\section{Perceptrón multicapa}

\section{SVR}

\section{Stacking}



\begin{thebibliography}{10}


\bibitem{Abel} 
    \textsc{Abel, N.\,H.}: 
    Beweis eines Ausdrucks, von welchem die Binomial-Formel ein einzelner Fall ist. 
    \textit{J. Reine angew. Math.} {\bf1} (1826), 159--160.

\bibitem{S-W}
    \textsc{Stein, E.\,M. and Weiss, G.}
    \textit{Introduction to  Fourier analysis on Euclidean spaces.}
    Princeton Mathematical Series~32, Princeton University Press, Princeton, NJ, 1971.
    
    
\end{thebibliography}
\cleardoublepage






















\end{document}

